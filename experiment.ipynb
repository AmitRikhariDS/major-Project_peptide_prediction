{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f821fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Using cached numpy-2.1.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\masters\\project\\venv_p\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in d:\\masters\\project\\venv_p\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in d:\\masters\\project\\venv_p\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in d:\\masters\\project\\venv_p\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\masters\\project\\venv_p\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\masters\\project\\venv_p\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.19.0-cp310-cp310-win_amd64.whl (375.7 MB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Using cached wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, opt-einsum, numpy, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, astunparse, werkzeug, requests, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed MarkupSafe-3.0.2 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 idna-3.10 libclang-18.1.1 markdown-3.8 numpy-2.1.3 opt-einsum-3.4.0 protobuf-5.29.4 requests-2.32.3 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.0.1 urllib3-2.4.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Masters\\project\\venv_p\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Masters\\project\\venv_p\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311352fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2125665429.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = tf.keras.Sequential([\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae47cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector = preprocess_input('TDIELEIYGMEGIPEK', Feature_50)\n",
    "input_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(seq, Feature_50, max_len=50):\n",
    "    seq = seq.upper()\n",
    "    feature_seq = [Feature_50.get(aa, np.zeros(50)) for aa in seq]\n",
    "    padded = pad_sequences([feature_seq], maxlen=max_len, padding='post', dtype='float32')\n",
    "    return np.array(padded)\n",
    "\n",
    "input_seq = tokenizer.texts_to_sequences([peptide])\n",
    "padded_seq = pad_sequences(input_seq, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8acab",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'venv_p (Python 3.10.17)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load selected top 50 features\n",
    "with open(\"data/Feature_50.pkl\", \"rb\") as f:\n",
    "    Feature_50 = pickle.load(f)\n",
    "\n",
    "# Define constants\n",
    "max_length = 50\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'  # Standard amino acids\n",
    "AA_TO_INDEX = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "\n",
    "# Pad peptide sequence to max length\n",
    "def pad_sequence(seq, max_length):\n",
    "    return seq.ljust(max_length, 'X')[:max_length]\n",
    "\n",
    "# One-hot encode a sequence\n",
    "def one_hot_encode(seq, aa_to_index):\n",
    "    num_classes = len(aa_to_index)\n",
    "    encoded = np.zeros((max_length, num_classes), dtype=int)\n",
    "    for i, aa in enumerate(seq):\n",
    "        if aa in aa_to_index:\n",
    "            encoded[i, aa_to_index[aa]] = 1\n",
    "    return encoded.flatten()\n",
    "\n",
    "# Main preprocessing function for model input\n",
    "def preprocess_input(seq):\n",
    "    padded = pad_sequence(seq.upper(), max_length)\n",
    "    encoded = one_hot_encode(padded, AA_TO_INDEX)\n",
    "\n",
    "    # Convert to DataFrame and filter top features\n",
    "    column_names = [f'{aa}_Pos_{pos+1}' for pos in range(max_length) for aa in amino_acids]\n",
    "    df = pd.DataFrame([encoded], columns=column_names)\n",
    "    return df[Feature_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec15e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
